<p align="center">
<img src=../../README_images/APRIL_HEADER.png width="400">
</p>

<h1 align="center">Welcome to the April playground! Hands on with container orchestration using Docker Swarm and Kubernetes</h1>

[The Playground link](https://github.com/DevOpsPlayground/Hands-on-with-container-orchestration-using-Docker-Swarm-and-Kubernetes.git)

# Intro

Hello and welcome to the April 2020 playground DIY.

This playground will help you to understand the basics of the container orchestration tools. It will be on average ~60 minutes which should give you enough understanding to further explore one of the tools (or both) with a little help from the documentation.

If you see <something> formatted this way It either requires an input from you or refers to the output specific to your environment.

You will have two instances, which will be initially configured in the same way. During this playground We will configure one of your instances as a master/manager, and the second will be a worker. We will be performing operations on both of them during this session so please follow the instructions carefully.

# Check Before You Start!

We will be building the required infrastructure using Terraform so if you do not have this currently installed please [visit the Hashicorp website](https://learn.hashicorp.com/tutorials/terraform/install-cli) for how to do this.

**All infrastructure will require an AWS account so please make sure you have run through the installation process for AWS CLI and AWS config in the [root README.md file](../../README.md)**

## Important:

Before we get started there are a few things that are worth noting. We have set the defaults to a number of variables that can be changed within the `variables.tf` file if required:

* The current code will build two EC2 instances one for the `master/manager` and a second for the `worker`.
* The `master/manager` instance and `worker` instance will both run two docker containers. One with the project directory uploaded and wetty installed allowing SSH from the web. The other has VS Code installed providing a text editor to amend and save changed code if you wish to this.
* If you prefer to use VIM then you can ! If not, you can use the VS Code IDE.
* If you have your own hosted zone set up in Route53 then you can use your own domain for each instance rather than the IPs. To do this uncomment lines `51-67` in `main.tf`, lines `25-31` in `outputs.tf` and lines `23-27` in `variables.tf`
* The default `region` is set to `eu-west-2`
* The default `deploy_count` is set to 1. Change this if you are running the playground for more than one user.
* The default `instance_type` is set to `t2.medium` as the t2.micro does not have enough resource to efficiently run the workstation. This on-demand pricing is $0.0464 per hour (£0.034 per hour) per instance. Should you leave this running for 1 month (720 hours), you would be charged $33.63 (£24.48) per instance. **make sure you delete the instance when finished with the playground!**

# Build Infrastructure

Make sure you are in the `April_2020` directory and run:

```
$ terraform init
```  
This will initialise a working directory containing our Terraform configuration files. This command is always safe to run multiple times, to bring the working directory up to date with changes in the configuration. You should see the following:

<p align="center">
<img src=../../README_images/tf_init.png width="600">
</p>

Then run:
```
$ terraform plan
```

This command is used to create an execution plan. Terraform performs a refresh, unless explicitly disabled, and then determines what actions are necessary to achieve the desired state specified in the configuration files.

This command is a convenient way to check whether the execution plan for a set of changes matches your expectations without making any changes to real resources or to the state. For example, terraform plan might be run before committing a change to version control, to create confidence that it will behave as expected. The plan will be fairly long but if all went well you should see the following in your terminal:

<p align="center">
<img src=../../README_images/april-20-plan.png width="600">
</p>

Finally you need to run:
```
$ terraform apply
```

This command is used to apply the changes required to reach the desired state of the configuration, or the pre-determined set of actions generated by a terraform plan execution plan. You will be prompted to enter a value to perform the action. Type `yes` as the value and hit enter.

Terraform will now build our required AWS infrastructure. This should complete after a minute or so showing the following:

<p align="center">
<img src=../../README_images/april-20-apply.png width="600">
</p>

> IMPORTANT! - make a note of the `MasterNodePassword` and `WorkerNodePassword` as these are auto-generated and will only be shown once. If lost you may need to build your instances again.

Once the apply has completed your EC2 instance(s) will now be initialising and running the required script(s). Once the `instances states` have changed to `Running` they may take a further 4/5 minutes to install all the required dependencies. 

## Access

To access your instances check outputs in terminal after running `terraform apply`:

* Workstation instance - <MasterNode_IP>/wetty e.g. 318.130.177.57/wetty
* Remote Host instance - <WorkerNode_IP>/wetty e.g. 318.131.177.57/wetty
browser e.g. 18.130.177.57:3000/wetty
* IDE access - <MasterNode_IP>:8000 in browser e.g. 318.130.177.57:8000
* Master Node password - provided at the end of terraform apply
* Worker Node password - provided at the end of terraform apply
## Agenda

The hands-on session will be divided to four parts:
- [Deploy web application as standalone container](docs/standalone.md):
  - We will create a docker image containing simple web application using Dockerfile.
  - We will run the container using previously created images.
  - We will investigate and access our deployment.
- [Deploy and use load-balancer](docs/lb.md):
  - We will create a load-balancer configuration.
  - We will run the container using official ha-proxy images.
  - We will mount our configuration as a volume.
  - We will access our application through the load-balancer/
- [Deploy application on the Swarm cluster](docs/swarm.md):
  - We will initialize Swarm cluster and add worker node.
  - We will deploy and scale our application.
  - We will simulate the failure of one the nodes.
  - We will "drain" one of the nodes to see how routing mesh works.
- [Deploy application on the Kubernetes cluster](docs/k8s.md):
  - We will initialize the Kubernetes cluster.
  - We will deploy our application to the Kubernetes cluster.
  - We will expose our deployment using NodePort resource.
  - We will scale our application and investigate its behavior.

## What skills/capabilities you will have after the workshop:
- You will be able to containerize and deploy an application
- You will be able to set up Docker Swarm and Kubernetes cluster
- You will be able to deploy your applications using orchestration tools

## Clean up

**Once you have finished playing around remember to delete the infrastructure to avoid any additional running charges as mentioned**

Make sure you are in the `April_2020` directory and run the following command:
```
$ terraform destroy
```
The command does exactly what it says on the tin. Infrastructure managed by Terraform will be destroyed. This will ask for confirmation before destroying, so please type `yes` when prompted.

**Again, you will continue to be charged by AWS if you do not run this final step**


